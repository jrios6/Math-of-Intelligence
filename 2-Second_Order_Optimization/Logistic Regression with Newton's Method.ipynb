{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Newton's Method\n",
    "\n",
    "This is a response to Siraj Raval's [Coding Challenge](https://github.com/llSourcell/Second_Order_Optimization_Newtons_Method) \n",
    "In this notebook, we will be building a logistic regression model using Newton's 2nd Order Optimization Method instead of the regular gradient descent.\n",
    "\n",
    "We will be using the Kaggle [Breast Cancer Wisconsin](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data) Data Set to classify if a tumour is malignant or benign, based on 30 features, such as the mean radius.\n",
    "\n",
    "References:  \n",
    "[Logistic Regression Newton's Method](https://github.com/llSourcell/logistic_regression_newtons_method) by Siraj Raval  \n",
    "[CS229 - Logistic Regression](http://cs229.stanford.edu/notes/cs229-notes1.pdf) by Andrew Ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "We will begin by doing some simple data cleaning and preparation before delving into the logistic regression and newton's method formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "0         0.2419           ...                    25.38          17.33   \n",
       "1         0.1812           ...                    24.99          23.41   \n",
       "2         0.2069           ...                    23.57          25.53   \n",
       "3         0.2597           ...                    14.91          26.50   \n",
       "4         0.1809           ...                    22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "## Dropping a unused fields\n",
    "fields_to_drop = ['id', 'Unnamed: 32'] \n",
    "data = data.drop(fields_to_drop, axis=1)\n",
    "\n",
    "## Converting diagnosis to int - 1 for malignant, 0 - for benign\n",
    "d = {'M': 1, 'B': 0}\n",
    "data['diagnosis'] = data['diagnosis'].map(d)\n",
    "\n",
    "## Visualising the data set\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Using 10% of dataset for testing, 10% for CV\n",
    "test_split_idx = int(data.shape[0]*0.9) \n",
    "val_split_idx = int(data.shape[0]*0.8) \n",
    "\n",
    "test_data = data[test_split_idx:]\n",
    "val_data = data[val_split_idx:test_split_idx]\n",
    "data = data[:val_split_idx]\n",
    "\n",
    "## Separating data to features and targets\n",
    "train_Y, train_X = data['diagnosis'], data.drop('diagnosis', axis=1)\n",
    "val_Y, val_X = val_data['diagnosis'], val_data.drop('diagnosis', axis=1)\n",
    "test_Y, test_X = test_data['diagnosis'], test_data.drop('diagnosis', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean           ...             radius_worst  \\\n",
       "0                 0.07871           ...                    25.38   \n",
       "1                 0.05667           ...                    24.99   \n",
       "2                 0.05999           ...                    23.57   \n",
       "3                 0.09744           ...                    14.91   \n",
       "4                 0.05883           ...                    22.54   \n",
       "\n",
       "   texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0          17.33           184.60      2019.0            0.1622   \n",
       "1          23.41           158.80      1956.0            0.1238   \n",
       "2          25.53           152.50      1709.0            0.1444   \n",
       "3          26.50            98.87       567.7            0.2098   \n",
       "4          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Logistic Regression is a method in machine learning for classification problems to output discrete values. For example, given an input of the tumour size, the logistic function can classify it as malignant (1) or benign (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's Method\n",
    "Newton's method is a second-order optimization algorithm that can help us find the best weights in our logistic function in fewer iterations compared to batch gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newton_step(curr, y, X, lam=None):\n",
    "    p = np.array(sigmoid(X.dot(curr[:,0])), ndmin=2).T\n",
    "    W = np.diag((p*(1-p))[:,0])\n",
    "    hessian = X.T.dot(W).dot(X)\n",
    "    grad = X.T.dot(y-p)\n",
    "    \n",
    "    step = np.dot(np.linalg.inv(hessian), grad)\n",
    "    beta = curr + step\n",
    "    \n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_model(X, y, beta):\n",
    "    prob = np.array(sigmoid(X.dot(beta)))\n",
    "    \n",
    "    ## Converting prob to prediction, >.5 = True, <.5 = False\n",
    "    prob = np.greater(prob, 0.5*np.ones((prob.shape[1],1)))\n",
    "    accuracy = np.count_nonzero(np.equal(prob, y))/prob.shape[0] * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0\n",
      "Validation Accuracy: 21.052631578947366%\n",
      "Iteration: 1\n",
      "Validation Accuracy: 78.94736842105263%\n",
      "Iteration: 2\n",
      "Validation Accuracy: 100.0%\n",
      "Iteration: 3\n",
      "Validation Accuracy: 100.0%\n",
      "Iteration: 4\n",
      "Validation Accuracy: 96.49122807017544%\n",
      "Iteration: 5\n",
      "Validation Accuracy: 96.49122807017544%\n",
      "Iteration: 6\n",
      "Validation Accuracy: 96.49122807017544%\n",
      "Iteration: 7\n",
      "Validation Accuracy: 96.49122807017544%\n",
      "Iteration: 8\n",
      "Validation Accuracy: 96.49122807017544%\n",
      "Iteration: 9\n",
      "Validation Accuracy: 96.49122807017544%\n"
     ]
    }
   ],
   "source": [
    "beta_old, beta = np.ones((30,1)), np.zeros((30,1))\n",
    "iter_count = 0\n",
    "\n",
    "while iter_count < 10:\n",
    "    print('Iteration: {}'.format(iter_count))\n",
    "    print('Validation Accuracy: {}%'.format(\n",
    "        test_model(val_X, val_Y.to_frame(), beta_old)))\n",
    "    beta_old = beta\n",
    "    beta = newton_step(beta, train_Y.to_frame(), train_X, None)\n",
    "    iter_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "As observed, using Newton's Method, the model converges in very few number of iterations and achieves a high test accuracy of 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 10 Iterations\n",
      "Test Accuracy: 94.73684210526315%\n"
     ]
    }
   ],
   "source": [
    "print('After {} Iterations'.format(iter_count))\n",
    "print('Test Accuracy: {}%'.format(\n",
    "        test_model(test_X, test_Y.to_frame(), beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -1.04668264e+02]\n",
      " [  2.09116266e+00]\n",
      " [  5.18570272e+00]\n",
      " [  5.49310769e-01]\n",
      " [  1.07108656e+03]\n",
      " [ -5.45177727e+02]\n",
      " [ -2.40565221e+02]\n",
      " [  9.40406906e+02]\n",
      " [ -2.97600445e+02]\n",
      " [ -6.44473718e+02]\n",
      " [  5.90441009e+00]\n",
      " [ -3.29270899e+00]\n",
      " [ -1.39144775e+01]\n",
      " [  1.37715174e+00]\n",
      " [ -2.21457011e+03]\n",
      " [  8.82629681e+02]\n",
      " [ -6.88970455e+02]\n",
      " [  5.39779015e+03]\n",
      " [ -6.58095383e+02]\n",
      " [ -8.33603494e+03]\n",
      " [  2.62726536e+01]\n",
      " [  1.49213205e+00]\n",
      " [  1.34908625e+00]\n",
      " [ -1.25026607e-01]\n",
      " [ -4.96292601e+01]\n",
      " [ -1.04612365e+02]\n",
      " [  1.61970212e+02]\n",
      " [ -2.63811531e+02]\n",
      " [  2.08095853e+02]\n",
      " [  9.80844063e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Ascent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd_step(curr, y, X, lr=0.0000001):\n",
    "    hx = X.dot(curr)\n",
    "    p = np.array(sigmoid(hx))\n",
    "    change = lr * (X.T.dot(y-p))\n",
    "    beta = curr + change\n",
    "    return beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Validation Accuracy: 78.94736842105263%\n",
      "Epoch: 10\n",
      "Validation Accuracy: 43.859649122807014%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiarui1/anaconda/envs/dlp3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\n",
      "Validation Accuracy: 91.22807017543859%\n",
      "Epoch: 30\n",
      "Validation Accuracy: 87.71929824561403%\n",
      "Epoch: 40\n",
      "Validation Accuracy: 92.98245614035088%\n",
      "Epoch: 50\n",
      "Validation Accuracy: 92.98245614035088%\n",
      "Epoch: 60\n",
      "Validation Accuracy: 87.71929824561403%\n",
      "Epoch: 70\n",
      "Validation Accuracy: 92.98245614035088%\n",
      "Epoch: 80\n",
      "Validation Accuracy: 92.98245614035088%\n",
      "Epoch: 90\n",
      "Validation Accuracy: 92.98245614035088%\n"
     ]
    }
   ],
   "source": [
    "batch_size = 50\n",
    "lr = 0.0001\n",
    "beta_old, beta = np.ones((30,1)), np.zeros((30,1))\n",
    "iter_count = 0\n",
    "\n",
    "while iter_count < 100:\n",
    "    if iter_count % 10 == 0:\n",
    "        print('Epoch: {}'.format(iter_count))\n",
    "        print('Validation Accuracy: {}%'.format(\n",
    "            test_model(val_X, val_Y.to_frame(), beta)))\n",
    "    beta_old = beta\n",
    "    for i in range(0, train_X.shape[0], batch_size):\n",
    "        beta = sgd_step(beta, train_Y[i:i+batch_size].to_frame(), \n",
    "                        train_X[i:i+batch_size], lr)\n",
    "    iter_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "While with batch gradient descent achieves an accuracy of 94% after 100 iterations, a learning rate has to be determined and set, alongside with the batch size. Notice that the beta values learnt by the function doe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 Iterations\n",
      "Test Accuracy: 94.73684210526315%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiarui1/anaconda/envs/dlp3/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "print('After {} Iterations'.format(iter_count))\n",
    "print('Test Accuracy: {}%'.format(\n",
    "        test_model(test_X, test_Y.to_frame(), beta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         diagnosis\n",
      "radius_mean              -1.879485\n",
      "texture_mean             -2.683234\n",
      "perimeter_mean          -10.991690\n",
      "area_mean                -5.679405\n",
      "smoothness_mean          -0.018427\n",
      "compactness_mean          0.007203\n",
      "concavity_mean            0.029249\n",
      "concave points_mean       0.013066\n",
      "symmetry_mean            -0.035483\n",
      "fractal_dimension_mean   -0.013972\n",
      "radius_se                -0.017074\n",
      "texture_se               -0.211381\n",
      "perimeter_se              0.005227\n",
      "area_se                   3.713985\n",
      "smoothness_se            -0.001303\n",
      "compactness_se            0.001727\n",
      "concavity_se              0.002433\n",
      "concave points_se         0.000225\n",
      "symmetry_se              -0.003774\n",
      "fractal_dimension_se     -0.000324\n",
      "radius_worst             -1.955783\n",
      "texture_worst            -3.436921\n",
      "perimeter_worst         -10.770612\n",
      "area_worst                6.674729\n",
      "smoothness_worst         -0.022946\n",
      "compactness_worst         0.039465\n",
      "concavity_worst           0.064051\n",
      "concave points_worst      0.016582\n",
      "symmetry_worst           -0.045210\n",
      "fractal_dimension_worst  -0.012370\n"
     ]
    }
   ],
   "source": [
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
